{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#“In God we trust. All others must bring data.” – W. Edwards Deming, statistician"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power of Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# king - man + woman \n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# biggest - big + small \n",
    "model.most_similar(positive=['biggest','small'], negative=['big'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reading blog post from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join('data')\n",
    "print DATA_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_post_list= []\n",
    "female_post_list= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_post_list= pickle.load(male_file)\n",
    "    print len(male_post_list)\n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_post_list = pickle.load(female_file)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(female_post_list),female_post_list[1]\n",
    "print len(male_post_list),male_post_list[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(female_post_list),len(male_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_male_post_list = []\n",
    "clean_female_post_list = []\n",
    "\n",
    "for post_male in male_post_list:\n",
    "    if len(post_male) == 0:\n",
    "        continue\n",
    "    clean_male_post_list.append(post_male)\n",
    "\n",
    "for post_female in female_post_list:\n",
    "    if len(post_female) == 0:\n",
    "        continue\n",
    "    clean_female_post_list.append(post_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(clean_male_post_list),len(clean_female_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for post in clean_male_post_list:\n",
    "    if len(post) == 0:\n",
    "        print \"empty\"\n",
    "\n",
    "for post in clean_female_post_list:\n",
    "    if len(post) == 0:\n",
    "        print \"empty\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have the input data, building data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "concatenate_array = np.concatenate((np.zeros(len(clean_male_post_list)),np.ones(len(clean_female_post_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(concatenate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,male_female_train,male_female_test = train_test_split(np.concatenate((clean_male_post_list,clean_female_post_list)),concatenate_array,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape[0],male_female_train.shape[0],x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelizeReviews(reviews,label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        if len(v) == 0:\n",
    "            continue\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v,[label]))\n",
    "    return labelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_label = labelizeReviews(x_train,'TRAIN')\n",
    "x_test_label = labelizeReviews(x_test,'TEST')\n",
    "\n",
    "print len(x_train_label),len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We have labelized reviews, now building DBOW and DM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dm defines the training algorithm. By default (dm=1), distributed memory is used. Otherwise, dbow is employed.\n",
    "\n",
    "#size is the dimensionality of the feature vectors.\n",
    "\n",
    "#window is the maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "#alpha is the initial learning rate (will linearly drop to zero as training progresses).\n",
    "\n",
    "#seed = for the random number generator.\n",
    "\n",
    "#min_count = ignore all words with total frequency lower than this.\n",
    "\n",
    "#sample = threshold for configuring which higher-frequency words are randomly downsampled;\n",
    "#default is 0 (off), useful value is 1e-5.\n",
    "#workers = use this many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "#hs = if 1 (default), hierarchical sampling will be used for model training (else set to 0).\n",
    "\n",
    "#negative = if > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20).\n",
    "\n",
    "#dm_mean = if 0 (default), use the sum of the context word vectors. If 1, use the mean. Only applies when dm is used.\n",
    "\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=20)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=20,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dm.build_vocab(np.concatenate((x_train_label,x_test_label)))\n",
    "model_dbow.build_vocab(np.concatenate((x_train_label,x_test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_label_np = np.array(x_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_label_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(x_train_label_np.shape[0])\n",
    "    model_dm.train(x_train_label_np[perm])\n",
    "    model_dbow.train(x_train_label_np[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVecs(model,corpus,size):\n",
    "    vecs = [np.array(model[z.labels[0]]).reshape((1,size)) for z in corpus]\n",
    "    return np.concatenate(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model_dm,x_train_label_np,size)\n",
    "train_vecs_dbow = getVecs(model_dbow,x_train_label_np,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs = np.hstack((train_vecs_dm,train_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_label_np = np.array(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(x_test_label_np.shape[0])\n",
    "    model_dm.train(x_test_label_np[perm])\n",
    "    model_dbow.train(x_test_label_np[perm])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vecs_dm = getVecs(model_dm,x_test_label_np,size)\n",
    "test_vecs_dbow = getVecs(model_dbow,x_test_label_np,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_vecs = np.hstack((test_vecs_dm,test_vecs_dbow))\n",
    "print test_vecs_dm.shape,test_vecs_dbow.shape,male_female_train.shape,male_female_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We have all the vectors now, we have to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrl1 = SGDClassifier(loss='log',penalty='l1')\n",
    "lrl2 = SGDClassifier(loss='log',penalty='l2')\n",
    "print train_vecs.shape[0],male_female_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrl1.fit(train_vecs,male_female_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Test Accuracy : %.2f' %lrl1.score(test_vecs,male_female_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrl2.fit(train_vecs,male_female_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Test Accuracy : %.2f' %lrl2.score(test_vecs,male_female_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_l1_kf = KFold(n=train_vecs.shape[0],n_folds=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_l1_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_vecs_df = pd.DataFrame(train_vecs)\n",
    "target_np = np.array(male_female_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_vecs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_vecs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_l1_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_l1_metrics = []\n",
    "for train_index, validate_index in sgd_l1_kf:\n",
    "    sample_train,sample_validate = trained_vecs_df.loc[train_index],trained_vecs_df.loc[validate_index]\n",
    "    \n",
    "    sample_train_target,sample_validate_target = male_female_train[train_index],male_female_train[validate_index]\n",
    "    \n",
    "    #print sample_train.shape,sample_validate.shape,sample_train_target.shape,sample_validate_target.shape\n",
    "    \n",
    "    sgd_l1 = SGDClassifier(loss='log',penalty='l1')\n",
    "    \n",
    "    sgd_l1.fit(sample_train,sample_train_target)\n",
    "    \n",
    "    sgd_l1_predicted = sgd_l1.predict(sample_validate)\n",
    "    \n",
    "    sgd_l1_predicted_copy = sgd_l1_predicted.copy()\n",
    "    \n",
    "    sgd_l1_predicted[sgd_l1_predicted > 0.5] = 1\n",
    "    sgd_l1_predicted[sgd_l1_predicted <= 0.5] = 0\n",
    "  \n",
    "    \n",
    "    sgd_l1_analysis = pd.concat([pd.Series(sample_validate_target),pd.Series(sgd_l1_predicted)],axis=1)\n",
    "\n",
    "    sgd_l1_analysis.columns = ['actual','prediction']\n",
    "    \n",
    "    sgd_l1_auc = metrics.roc_auc_score(sgd_l1_analysis.actual,sgd_l1_analysis.prediction)\n",
    "        \n",
    "    sgd_l1_metrics.append((sgd_l1_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_l1_metrics_df = pd.DataFrame(sgd_l1_metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(sgd_l1_analysis.actual, sgd_l1_predicted_copy)\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# RNN using LSTM \n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import one_hot,text_to_word_sequence,base_filter\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text processing - one hot builds index of the words\n",
    "male_one_hot = []\n",
    "female_one_hot = []\n",
    "n = 30000\n",
    "for post in clean_male_post_list:\n",
    "    try:\n",
    "        male_one_hot.append(one_hot(post,n,split=\" \",filters=base_filter(),lower=True))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for post in clean_female_post_list:\n",
    "    try:\n",
    "        female_one_hot.append(one_hot(post,n,split=\" \",filters=base_filter(),lower=True))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "concatenate_array_rnn = np.concatenate((np.zeros(len(male_one_hot)),np.ones(len(female_one_hot))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((female_one_hot,male_one_hot)),concatenate_array_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "dimension = 128\n",
    "input_dimension = 128\n",
    "output_dimension = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, dimension))\n",
    "model.add(LSTM(input_dimension, output_dimension))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_rnn,y_train_rnn,batch_size=32,nb_epoch=4,validation_data=(x_test_rnn,y_test_rnn),show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score,acc = model.evaluate(x_test_rnn,y_test_rnn,batch_size=32,show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TFIDF Vectorizer as an input instead of one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', norm='l2')\n",
    "tfidf_male = vectorizer.fit_transform(clean_male_post_list)\n",
    "tfidf_female = vectorizer.fit_transform(clean_female_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened_array_tfidf_male = tfidf_male.toarray()\n",
    "flattened_array_tfidf_female = tfidf_male.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatenate_array_rnn = np.concatenate((np.zeros(len(flattened_array_tfidf_male)),np.ones(len(flattened_array_tfidf_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((flattened_array_tfidf_male,flattened_array_tfidf_female)),concatenate_array_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "# x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "# x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "# print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "# print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, 128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_rnn,y_train_rnn,batch_size=32,nb_epoch=4,validation_data=(x_test_rnn,y_test_rnn),show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score,acc = model.evaluate(x_test_rnn,y_test_rnn,batch_size=32,show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Generation using RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading all the male text data into one string\n",
    "male_post = ' '.join(clean_male_post_list[:2])\n",
    "\n",
    "#building character set for the male posts\n",
    "character_set_male = set(male_post)\n",
    "#building two indices - character index and index of character\n",
    "char_indices = dict((c, i) for i, c in enumerate(character_set_male))\n",
    "indices_char = dict((i, c) for i, c in enumerate(character_set_male))\n",
    "\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(male_post) - maxlen, step):\n",
    "    sentences.append(male_post[i : i + maxlen])\n",
    "    next_chars.append(male_post[i + maxlen])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorisation of input\n",
    "x_male = np.zeros((len(male_post),maxlen,len(character_set_male)),dtype=np.bool)\n",
    "y_male = np.zeros((len(male_post),len(character_set_male)),dtype=np.bool)\n",
    "\n",
    "print x_male.shape,y_male.shape\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_male[i, t, char_indices[char]] = 1\n",
    "    y_male[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print x_male.shape,y_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Building the model to generate text with 2 layers\n",
    "auto_text_generating_male_model = Sequential()\n",
    "auto_text_generating_male_model.add(LSTM(len(character_set_male),512,return_sequences=True))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(LSTM(512,512,return_sequences=False))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(Dense(512,len(character_set_male)))\n",
    "auto_text_generating_male_model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_text_generating_male_model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to sample an index from a probability array\n",
    "def sample(a, diversity=0.75):\n",
    "    if random.random() > diversity:\n",
    "        return np.argmax(a)\n",
    "    while 1:\n",
    "        i = random.randint(0, len(a)-1)\n",
    "        if a[i] > random.random():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1,10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    auto_text_generating_male_model.fit(x_male, y_male, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(male_post) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = male_post[start_index : start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for iteration in range(400):\n",
    "            try:\n",
    "                x = np.zeros((1, maxlen, len(character_set_male)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = auto_text_generating_male_model.predict(x, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                #sys.stdout.write(next_char)\n",
    "                #sys.stdout.flush()\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        print sentence\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
