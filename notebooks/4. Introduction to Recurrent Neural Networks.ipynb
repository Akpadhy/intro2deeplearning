{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> “In God we trust. All others must bring data.” – W. Edwards Deming, statistician"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "### What?\n",
    "Convert words to vectors in a high dimensional space. Each dimension denotes an aspect like gender, type of object / word.\n",
    "\n",
    "### Why?\n",
    "By converting words to vectors we build relations between words. More similar the words in a dimension, more closer their scores are.\n",
    "\n",
    "### Example\n",
    "_W(green) = (1.2, 0.98, 0.05, ...)_\n",
    "\n",
    "_W(red) = (1.1, 0.2, 0.5, ...)_\n",
    "\n",
    "Here the vector values of _green_ and _red_ are very similar in one dimension because they both are colours. The value for second dimension is very different because red might be depicting something negative in the training data while green is used for positiveness.\n",
    "\n",
    "By vectorizing we are indirectly building different kind of relations between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do: read blog data before this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading blog post from data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIRECTORY = os.path.join('../data')\n",
    "print DATA_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_posts = []\n",
    "female_post = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_posts= pickle.load(male_file)\n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_posts = pickle.load(female_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252\n",
      "2611\n"
     ]
    }
   ],
   "source": [
    "print len(female_posts)\n",
    "print len(male_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words\n",
    "```from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_male_posts = []\n",
    "filtered_female_posts = []\n",
    "\n",
    "for post_male in male_posts:\n",
    "    if len(post_male) == 0:\n",
    "        continue\n",
    "    filtered_male_posts.append(post_male)\n",
    "\n",
    "for post_female in female_posts:\n",
    "    if len(post_female) == 0:\n",
    "        continue\n",
    "    filtered_female_posts.append(post_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2247\n",
      "2595\n"
     ]
    }
   ],
   "source": [
    "print len(filtered_female_posts)\n",
    "print len(filtered_male_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_female_posts = map(lambda x:unicode(x), filtered_female_posts)\n",
    "filtered_male_posts = map(lambda x: unicode(x), filtered_male_posts)\n",
    "posts = filtered_female_posts + filtered_male_posts    \n",
    "type(posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4842\n",
      "<type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "print len(posts)\n",
    "print type(posts[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences=map(lambda x: x.split(),posts[0:100]),iter=30,min_count=1)\n",
    "#w2v.build_vocab(posts[0].split('.'))\n",
    "#w2v.train(posts[0].split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Well,',\n",
       "  u'everyone',\n",
       "  u'got',\n",
       "  u'up',\n",
       "  u'and',\n",
       "  u'going',\n",
       "  u'this',\n",
       "  u'morning.',\n",
       "  u\"It's\",\n",
       "  u'still',\n",
       "  u'raining,',\n",
       "  u'but',\n",
       "  u\"that's\",\n",
       "  u'okay',\n",
       "  u'with',\n",
       "  u'me.',\n",
       "  u'Sort',\n",
       "  u'of',\n",
       "  u'suits',\n",
       "  u'my',\n",
       "  u'mood.',\n",
       "  u'I',\n",
       "  u'could',\n",
       "  u'easily',\n",
       "  u'have',\n",
       "  u'stayed',\n",
       "  u'home',\n",
       "  u'in',\n",
       "  u'bed',\n",
       "  u'with',\n",
       "  u'my',\n",
       "  u'book',\n",
       "  u'and',\n",
       "  u'the',\n",
       "  u'cats.',\n",
       "  u'This',\n",
       "  u'has',\n",
       "  u'been',\n",
       "  u'a',\n",
       "  u'lot',\n",
       "  u'of',\n",
       "  u'rain',\n",
       "  u'though!',\n",
       "  u'People',\n",
       "  u'have',\n",
       "  u'wet',\n",
       "  u'basements,',\n",
       "  u'there',\n",
       "  u'are',\n",
       "  u'lakes',\n",
       "  u'where',\n",
       "  u'there',\n",
       "  u'should',\n",
       "  u'be',\n",
       "  u'golf',\n",
       "  u'courses',\n",
       "  u'and',\n",
       "  u'fields,',\n",
       "  u'everything',\n",
       "  u'is',\n",
       "  u'green,',\n",
       "  u'green,',\n",
       "  u'green.',\n",
       "  u'But,',\n",
       "  u'it',\n",
       "  u'is',\n",
       "  u'supposed',\n",
       "  u'to',\n",
       "  u'be',\n",
       "  u'26',\n",
       "  u'degrees',\n",
       "  u'by',\n",
       "  u'Friday,',\n",
       "  u'so',\n",
       "  u\"we'll\",\n",
       "  u'be',\n",
       "  u'dealing',\n",
       "  u'with',\n",
       "  u'mosquitos',\n",
       "  u'next',\n",
       "  u'week.',\n",
       "  u'I',\n",
       "  u'heard',\n",
       "  u'Winnipeg',\n",
       "  u'described',\n",
       "  u'as',\n",
       "  u'an',\n",
       "  u'\"Old',\n",
       "  u'Testament\"',\n",
       "  u'city',\n",
       "  u'on',\n",
       "  u'urlLink',\n",
       "  u'CBC',\n",
       "  u'Radio',\n",
       "  u'One',\n",
       "  u'last',\n",
       "  u'week',\n",
       "  u'and',\n",
       "  u'it',\n",
       "  u'sort',\n",
       "  u'of',\n",
       "  u'rings',\n",
       "  u'true.',\n",
       "  u'Floods,',\n",
       "  u'infestations,',\n",
       "  u'etc.,',\n",
       "  u'etc..']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x.split() , posts[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Well, everyone got up and going this morning.  It\\'s still raining, but that\\'s okay with me.  Sort of suits my mood.  I could easily have stayed home in bed with my book and the cats.  This has been a lot of rain though!  People have wet basements, there are lakes where there should be golf courses and fields, everything is green, green, green.  But, it is supposed to be 26 degrees by Friday, so we\\'ll be dealing with mosquitos next week.  I heard Winnipeg described as an \"Old Testament\" city on  urlLink CBC Radio One  last week and it sort of rings true.  Floods, infestations, etc., etc..'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88632810653679395"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.similarity(u'Testament\"', u'\"Old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have the input data, building data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "concatenate_array = np.concatenate((np.zeros(len(filtered_male_posts)),np.ones(len(filtered_female_posts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4842"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenate_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create cross validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,male_female_train,male_female_test = train_test_split(np.concatenate((filtered_male_posts,filtered_female_posts)),concatenate_array,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3873,\n",
       " 3873,\n",
       " array([ u\"I watched Apocalypse Now a couple days ago. Man, what an amazing movie. I'm not really in the mood to write up a big post right now, so just go and watch it. Your jaw will drop at some of the visuals, too. I assure it.\",\n",
       "        u'The sun\\u2019s graceful fingers Tease the Brisbane River playfully My sunken soul is ignited with a sparkle As the sky meets the earth with such dancing glee  Bright yellow sunflowers Adorn green fields and my backyard Such pretty things of nature God\\u2019s creation to warm our cold hearts  A rainbow in the sky Reminds me of God\\u2019s covenant to man Never again will a flood destroy all life On His faithfulness man can always depend  The puffy white clouds Overflow with God\\u2019s glory As it rains His grace pours out Providing dry souls rest and recovery  All glory and praises to God For He has given me life and hope My King my Redeemer and my Lord  No more in darkness again I\\u2019ll grope',\n",
       "        u\"We went on our trip and it was fun. Nothing bad happened, except Al's zipper and button on his pants flew off. That was kinda funny. My mom was trying to drive my sister and her friend and she is an awful driver. Kat (my sister) said it almost killed her. I rode when she was driving and it scared me too. It was all fun and I think we all had a great time.\",\n",
       "        ...,\n",
       "        u\"Make sure to check out the  urlLink Thomas University Tech Services Website .  We are very proud of Buck's first experiment with flash animation.\",\n",
       "        u\"So my day has consisted of school, searching for an appropriate eCard for my friend's graduation, and eating home made baked beans.  Baked beans are good.  I'm running out of things totalk about... I better come up with another haiku...\",\n",
       "        u\"Written 22. April. 2003   Soon   Soon and soon and soon And this waiting makes me ache That I should be so close and yet so far But all I can do is wait.  Breathe through each moment move past each day bring myself  closer and closer and closer  To change to hope to life or something like it.  A chance granted with stipulations abundant- Don't fuck it up now. Just wait.  Wade through the ache walk past the restless imaginings Focus on right now.  Get the details right And everything falls into place Soon and soon and soon Wait.  Sweetest things they say Did they ever have to wait for this? Or mourn for past and future?  All inside my head.  Soon and soon and soon So I wait.\"], \n",
       "       dtype='<U38794'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0],male_female_train.shape[0],x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelizeReviews(reviews,label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        if len(v) == 0:\n",
    "            continue\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v,[label]))\n",
    "    return labelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3873 3873\n"
     ]
    }
   ],
   "source": [
    "x_train_label = labelizeReviews(x_train,'TRAIN')\n",
    "x_test_label = labelizeReviews(x_test,'TEST')\n",
    "\n",
    "print len(x_train_label),len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have labelized reviews, now building Doc2Vec models using Distibuted Memory (DM) and Distributed Bag of Words (DBoW)\n",
    "\n",
    "* **DM** - Given the context (set of paragraphs), predict the next word\n",
    "* **DBoW** - Given the word, predict the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dm defines the training algorithm. By default (dm=1), distributed memory is used. Otherwise, dbow is employed.\n",
    "\n",
    "#size is the dimensionality of the feature vectors.\n",
    "\n",
    "#window is the maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "#alpha is the initial learning rate (will linearly drop to zero as training progresses).\n",
    "\n",
    "#seed = for the random number generator.\n",
    "\n",
    "#min_count = ignore all words with total frequency lower than this.\n",
    "\n",
    "#sample = threshold for configuring which higher-frequency words are randomly downsampled;\n",
    "#default is 0 (off), useful value is 1e-5.\n",
    "#workers = use this many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "#hs = if 1 (default), hierarchical sampling will be used for model training (else set to 0).\n",
    "\n",
    "#negative = if > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20).\n",
    "\n",
    "#dm_mean = if 0 (default), use the sum of the context word vectors. If 1, use the mean. Only applies when dm is used.\n",
    "\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=20)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=20,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dm.build_vocab(np.concatenate((x_train_label,x_test_label)))\n",
    "model_dbow.build_vocab(np.concatenate((x_train_label,x_test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_label_np = np.array(x_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3873"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_label_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(x_train_label_np.shape[0])\n",
    "    model_dm.train(x_train_label_np[perm])\n",
    "    model_dbow.train(x_train_label_np[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVecs(model,corpus,size):\n",
    "    vecs = [np.array(model[z.labels[0]]).reshape((1,size)) for z in corpus]\n",
    "    return np.concatenate(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model_dm,x_train_label_np,size)\n",
    "train_vecs_dbow = getVecs(model_dbow,x_train_label_np,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs = np.hstack((train_vecs_dm,train_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3873, 600)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_label_np = np.array(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(x_test_label_np.shape[0])\n",
    "    model_dm.train(x_test_label_np[perm])\n",
    "    model_dbow.train(x_test_label_np[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vecs_dm = getVecs(model_dm,x_test_label_np,size)\n",
    "test_vecs_dbow = getVecs(model_dbow,x_test_label_np,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 300) (969, 300) (3873,) (969,)\n"
     ]
    }
   ],
   "source": [
    "test_vecs = np.hstack((test_vecs_dm,test_vecs_dbow))\n",
    "print test_vecs_dm.shape,test_vecs_dbow.shape,male_female_train.shape,male_female_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have all the vectors now, we have to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD classifier with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrl1 = SGDClassifier(loss='log',penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrl1.fit(train_vecs,male_female_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.60\n"
     ]
    }
   ],
   "source": [
    "print 'Test Accuracy : %.2f' %lrl1.score(test_vecs,male_female_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD classifier with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrl2 = SGDClassifier(loss='log',penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrl2.fit(train_vecs,male_female_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.56\n"
     ]
    }
   ],
   "source": [
    "print 'Test Accuracy : %.2f' %lrl2.score(test_vecs,male_female_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_l1_kf = KFold(n=train_vecs.shape[0],n_folds=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.KFold(n=3873, n_folds=5, shuffle=True, random_state=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_l1_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_vecs_df = pd.DataFrame(train_vecs)\n",
    "target_np = np.array(male_female_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027858</td>\n",
       "      <td>-0.070650</td>\n",
       "      <td>0.102599</td>\n",
       "      <td>-0.161764</td>\n",
       "      <td>-0.073124</td>\n",
       "      <td>0.138494</td>\n",
       "      <td>-0.156318</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.208494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118318</td>\n",
       "      <td>0.017203</td>\n",
       "      <td>0.104568</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.154994</td>\n",
       "      <td>-0.085229</td>\n",
       "      <td>-0.030719</td>\n",
       "      <td>-0.023108</td>\n",
       "      <td>0.164262</td>\n",
       "      <td>0.058002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.135392</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>0.091976</td>\n",
       "      <td>-0.073573</td>\n",
       "      <td>0.042152</td>\n",
       "      <td>0.331612</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>-0.030143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024347</td>\n",
       "      <td>0.133087</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>0.234445</td>\n",
       "      <td>-0.080593</td>\n",
       "      <td>-0.188176</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.181350</td>\n",
       "      <td>-0.181025</td>\n",
       "      <td>0.043562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076481</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.082829</td>\n",
       "      <td>-0.096777</td>\n",
       "      <td>0.187631</td>\n",
       "      <td>0.062384</td>\n",
       "      <td>-0.079174</td>\n",
       "      <td>0.142538</td>\n",
       "      <td>0.048883</td>\n",
       "      <td>0.275707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154620</td>\n",
       "      <td>0.071142</td>\n",
       "      <td>0.028617</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.095054</td>\n",
       "      <td>-0.121361</td>\n",
       "      <td>-0.008483</td>\n",
       "      <td>-0.025283</td>\n",
       "      <td>0.110582</td>\n",
       "      <td>0.116103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057386</td>\n",
       "      <td>0.125311</td>\n",
       "      <td>0.119550</td>\n",
       "      <td>-0.150341</td>\n",
       "      <td>0.161147</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>-0.043869</td>\n",
       "      <td>0.124369</td>\n",
       "      <td>0.108676</td>\n",
       "      <td>0.211083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075915</td>\n",
       "      <td>-0.061464</td>\n",
       "      <td>-0.073133</td>\n",
       "      <td>-0.237654</td>\n",
       "      <td>0.628716</td>\n",
       "      <td>-0.438802</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.316205</td>\n",
       "      <td>0.289040</td>\n",
       "      <td>-0.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022048</td>\n",
       "      <td>-0.012017</td>\n",
       "      <td>0.133229</td>\n",
       "      <td>-0.112235</td>\n",
       "      <td>0.130634</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>-0.100959</td>\n",
       "      <td>0.066252</td>\n",
       "      <td>0.047708</td>\n",
       "      <td>0.204717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180021</td>\n",
       "      <td>0.164485</td>\n",
       "      <td>-0.035360</td>\n",
       "      <td>-0.136693</td>\n",
       "      <td>0.365096</td>\n",
       "      <td>-0.226461</td>\n",
       "      <td>-0.229254</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>-0.122389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.027858 -0.070650  0.102599 -0.161764 -0.073124  0.138494 -0.156318   \n",
       "1  0.068548  0.135392  0.050947  0.087081  0.091976 -0.073573  0.042152   \n",
       "2  0.076481  0.025331  0.082829 -0.096777  0.187631  0.062384 -0.079174   \n",
       "3  0.057386  0.125311  0.119550 -0.150341  0.161147  0.078276 -0.043869   \n",
       "4 -0.022048 -0.012017  0.133229 -0.112235  0.130634 -0.007152 -0.100959   \n",
       "\n",
       "        7         8         9      ...          590       591       592  \\\n",
       "0  0.064498  0.059404  0.208494    ...    -0.118318  0.017203  0.104568   \n",
       "1  0.331612  0.043737 -0.030143    ...    -0.024347  0.133087  0.014530   \n",
       "2  0.142538  0.048883  0.275707    ...    -0.154620  0.071142  0.028617   \n",
       "3  0.124369  0.108676  0.211083    ...     0.075915 -0.061464 -0.073133   \n",
       "4  0.066252  0.047708  0.204717    ...    -0.180021  0.164485 -0.035360   \n",
       "\n",
       "        593       594       595       596       597       598       599  \n",
       "0  0.054840  0.154994 -0.085229 -0.030719 -0.023108  0.164262  0.058002  \n",
       "1  0.234445 -0.080593 -0.188176 -0.002635 -0.181350 -0.181025  0.043562  \n",
       "2  0.088915  0.095054 -0.121361 -0.008483 -0.025283  0.110582  0.116103  \n",
       "3 -0.237654  0.628716 -0.438802  0.003518  0.316205  0.289040 -0.253773  \n",
       "4 -0.136693  0.365096 -0.226461 -0.229254  0.060980  0.001445 -0.122389  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_vecs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3873, 600)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_vecs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.KFold(n=3873, n_folds=5, shuffle=True, random_state=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_l1_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_l1_metrics = []\n",
    "for train_index, validate_index in sgd_l1_kf:\n",
    "    sample_train,sample_validate = trained_vecs_df.loc[train_index],trained_vecs_df.loc[validate_index]\n",
    "    \n",
    "    sample_train_target,sample_validate_target = male_female_train[train_index],male_female_train[validate_index]\n",
    "    \n",
    "    #print sample_train.shape,sample_validate.shape,sample_train_target.shape,sample_validate_target.shape\n",
    "    \n",
    "    sgd_l1 = SGDClassifier(loss='log',penalty='l1')\n",
    "    \n",
    "    sgd_l1.fit(sample_train,sample_train_target)\n",
    "    \n",
    "    sgd_l1_predicted = sgd_l1.predict(sample_validate)\n",
    "    \n",
    "    sgd_l1_predicted_copy = sgd_l1_predicted.copy()\n",
    "    \n",
    "    sgd_l1_predicted[sgd_l1_predicted > 0.5] = 1\n",
    "    sgd_l1_predicted[sgd_l1_predicted <= 0.5] = 0\n",
    "  \n",
    "    \n",
    "    sgd_l1_analysis = pd.concat([pd.Series(sample_validate_target),pd.Series(sgd_l1_predicted)],axis=1)\n",
    "\n",
    "    sgd_l1_analysis.columns = ['actual','prediction']\n",
    "    \n",
    "    sgd_l1_auc = metrics.roc_auc_score(sgd_l1_analysis.actual,sgd_l1_analysis.prediction)\n",
    "        \n",
    "    sgd_l1_metrics.append((sgd_l1_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_l1_metrics_df = pd.DataFrame(sgd_l1_metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1257a1c50>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAH5ZJREFUeJzt3XmUFPW9/vH3x1EhBHC5qFcBDUYuRo+YEBeSiIyKMkBQ\n",
       "QBMCKKIImhzUc/RH1OgNk8UtLknUuMywKghuKCCIojBKXFAURSMYuIBhExQNQRSHYT6/P74DtOMw\n",
       "3dPT3dXL8zqHE5qpqf6kzvDwWF31LXN3REQkv+wV9QAiIpJ6CncRkTykcBcRyUMKdxGRPKRwFxHJ\n",
       "Qwp3EZE8FDfczWysmW0ws3fr2eYuM1tmZu+Y2Q9SO6KIiDRUIs19HFCypy+aWU/gKHdvDwwH7kvR\n",
       "bCIikqS44e7u84HP6tnkbGBCzbYLgP3N7JDUjCciIslIxTn31sDqmNdrgDYp2K+IiCQpVR+oWq3X\n",
       "WtNARCRCe6dgH2uBtjGv29T82deYmQJfRCQJ7l67QMeViuY+HRgMYGadgX+7+4a6NnR3/XJn1KhR\n",
       "kc+QLb90LHQsCv1YbNjg3Hqr0769891T3uKwP3TkrPG9WPuftbgn34njNnczmwx0BVqZ2WpgFLBP\n",
       "TVg/4O6zzKynmS0HtgIXJT2NiEgBqK6GF16AsjKYMwfO6VdJl9/eyIz193H7WbdzQccLMGtwWf+a\n",
       "uOHu7gMS2GZEo6YQESkA69fD+PFQXg4tW8Lw4XD5TYu4/IUhtN2rLW9f9jaHtTgsJe+lO1QjUFxc\n",
       "HPUIWUPHYjcdi93y6Vjs2AHPPAP9+sExx8DKlfDII7BgYSUbvjeK857qztU/upoZA2akLNgBrDHn\n",
       "dBr0RmaeqfcSEYna2rUwdiyMHg0HHwzDhsGAAdCiBSxav4gh04bQtmVbynqX1RvqZoYn8YFqKq6W\n",
       "ERERoKoKZs8O59L//nfo3x+efBI6dQpfr9xRyah5N3LfwtSdW98ThbuISCP9618wZkz41aZNOJf+\n",
       "8MPQvPnubWLbeirPre+Jwl1EJAnbt8PMmaGlL1gAAwfCrFnQsePXt6vcUcmNL2WmrcdSuIuINMDK\n",
       "leE8+rhxcOSRoaU//jg0a/bNbTPd1mMp3EVE4qishOnTwyWMb74JF1wAzz8frn6pc/uI2noshbuI\n",
       "yB4sXx5a+vjxcPTR4YqXadOgadM9f0+UbT2Wwl1EJMZXX8FTT4Vz6e++CxdeCC++CB061P992dDW\n",
       "YyncRUSADz4Ip10efDB8KDp8OPTpA02axP/ebGnrsRTuIlKwtm2DJ54ILf2DD2DIEHjlFTjqqMS+\n",
       "P9vaeiyFu4gUnH/8I7T0iRPhhz+EK66A3r1h330T30c2tvVYCncRKQhffAGPPRZCfeVKuOgieOMN\n",
       "aNeuYfvJ5rYeS+EuInlt8eJw2mXyZOjcGUaOhF69YO8k0i/b23oshbuI5J2tW8PKi2VlYQGvoUNh\n",
       "0SI4/PDk9pcrbT2Wwl1E8sZbb4XTLo88Al26wA03QElJci19p1xq67EU7iKS07ZsCadcysrgk0/g\n",
       "kkvC9emtWzduv7nY1mMp3EUk57jDwoUh0B9/HE4/Hf74RzjzTCgqavz+c7Wtx1K4i0jO2LwZJk0K\n",
       "p17+85/Q0t9/Hw49NDX7z/W2HkvhLiJZzR1eey209KeeCu38tttCW98rhQ8KzYe2HkuP2RORrPTZ\n",
       "Z/DQQ6Glb9sWlgO48MLwyLpUyva2rsfsiUjOcw+PpysvD0vs9uwJd98NXbtCOvI239p6LDV3EYnc\n",
       "pk1hwa6ysvB6+PCwZnqrVul5v2xv67HU3EUkp7hDRUVo6bNmwdlnh9//5Cfpaek75XNbj6XmLiIZ\n",
       "tXEjTJgQgrxJk9DSzz8fDjggve+bS209lpq7iGSt6mqYOzecdpkzB/r2DQHfuXN6W/pOhdLWY6m5\n",
       "i0jafPRReJD06NHQokVo6YMGwX77Zeb9c7Wtx1JzF5GssGNHaOdlZTBvHvzsZzBlCpxwQmZa+k6F\n",
       "2NZjKdxFJCXWroWxY2HMmHCVy/Dh4dRLixaZnSMf2noqKNxFJGk7dsAzz4QPR+fPh/79YepU6NQp\n",
       "mnkKva3HUriLSIP961+7W3rr1qGlT5oEzZtHM4/a+jcp3EUkIVVVMHNmOJf+2mswcGB43bFjtHOp\n",
       "rddN4S4i9Vq5MjT0sWPhyCNh2LDwLNJmzaKdS229fgp3EfmG7dvD2i5lZfDmm2EpgDlz4Nhjo54s\n",
       "UFuPT+EuIrssXx6uSZ8wATp0CC192jRo2jTqyQK19cQp3EUK3FdfhXXSy8th8WIYPDis+dKhQ9ST\n",
       "fZ3aesPEDXczKwH+AhQBo9391lpfbwVMBP67Zn+3u/v41I8qIqn0z3+GQJ8wAY47Llzx0qdPWO8l\n",
       "m6itJ6fecDezIuAeoBuwFnjDzKa7+5KYzUYAi9z9upqg/8DMJrp7VdqmFpGkbNsWrkMvK4OlS2HI\n",
       "EHjlFTjqqKgnq5vaevLiNfeTgOXuvgrAzKYA5wCx4b4e2HkxVEtgk4JdJLu8/35o6RMnhhuMLr8c\n",
       "eveGffeNerK6qa03Xrxwbw2sjnm9Bji51jblwFwzWwe0AH6euvFEJFlffhkuWSwrgxUr4OKL4fXX\n",
       "oV27qCern9p6asQL90SWcfwN8La7F5vZd4E5Zna8u2+pvWFpaemu3xcXF1NcXNyAUUUkEe++GwL9\n",
       "4YfDkrojR0KvXrB3ll8+obYeVFRUUFFR0ej91Lvkr5l1BkrdvaTm9XVAdeyHqmY2C7jR3V+uef0C\n",
       "cI27L6y1Ly35K5ImW7fCI4+EUF+7FoYODU398MOjniwxsW29rHeZ2nqMdC35uxBob2bfAdYB/YEB\n",
       "tbZZSvjA9WUzOwToAKxo6CAi0nCLFoVz6VOmQJcucMMNUFKS/S19J7X19Kn3R8Ddq8xsBPAs4VLI\n",
       "Me6+xMwurfn6A8BNwDgzewfYC/i1u3+a5rlFCtaWLTB5cgj1jRvhkkvC9elt2kQ9WcPo3Hp66UlM\n",
       "IjnAHRYuDIH+2GNw2mnhuvQzz4Sioqinaxi19YbRk5hE8tDmzeGD0bIy+M9/Qkt//3049NCoJ0uO\n",
       "2nrmqLmLZBl3WLAgBPqTT4Z2Pnw4nH467LVX1NMlR209eWruIjnus8/CTUZlZeFO0uHD4ZZb4OCD\n",
       "o56scdTWo6FwF4mQO7z8cgj0GTOgRw+4+27o2jWzD5NOB7X1aCncRSKwaRM8+GD4gNQ9tPQ77wwP\n",
       "ls4HauvRU7iLZIg7vPhiCPSZM+Hss+GBB+CUU3K/pe+ktp49FO4iabZxY1hWd/TosFDXsGHh1MuB\n",
       "B0Y9WWqprWcXhbtIGlRXw7x54Vz6c89B374wfnxY6yXfiqzaenZSuIuk0EcfhRAvL4cWLcK59LIy\n",
       "2G+/qCdLD7X17KVwF2mk6urw8OiyMpg7F847L6z1csIJ+dfSd1Jbz34Kd5EkrVsHY8eGc+mtWoWW\n",
       "Pn58aOz5TG09NyjcRRpgxw6YPTu09PnzoX//8Ni6Tp2iniz91NZzi8JdJAGrV8OYMaGpH3ZYaOmT\n",
       "JkHz5lFPlhlq67lH4S6yB1VV4Xr08nJ49VUYOBCefho6doz/vflCbT13KdxFalm1andLb9cuXJf+\n",
       "6KPQrFnUk2WW2npuU7iLANu3h7VdysrCuunnnx+uTz/22Kgnyzy19fygcJeC9vnncNNNMG4c/M//\n",
       "hHPpTz0FTZtGPVk01Nbzh8JdCtann0KvXuHUy7x5cPTRUU8UHbX1/KNwl4L00Udw1lnh12235e/N\n",
       "RolQW89POfpcF5HkrVoFXbqEa9QLOdgrd1Qyat4ouk/sztU/upoZA2Yo2POImrsUlCVLoHt3+PWv\n",
       "YcSIqKeJjtp6/lO4S8F480346U/h1lth8OCop4mGzq0XDoW7FISXXgoLepWVQZ8+UU8TDbX1wqJw\n",
       "l7w3axYMGQKTJ8MZZ0Q9TeaprRcmhbvktSlT4Morww1KJ58c9TSZp7ZeuBTukrfKyuD3v4fnn4fj\n",
       "jot6msxSWxeFu+SlP/0J7r8/PJD6u9+NeprMUlsXULhLnnGH668PSwjMnw+tW0c9UeaorUsshbvk\n",
       "jerqcO3666+Hq2NatYp6osxRW5faFO6SF7ZvD1fErF0bnmPasmXUE2WG2rrsicJdct6XX4alBKqr\n",
       "4Zln4FvfinqizFBbl/pobRnJaVu2QM+e4XF3Tz5ZGMGuNWEkEWrukrM++QR69IATToB77oGioqgn\n",
       "Sj+1dUmUmrvkpLVroWtX6NYN7r03/4NdbV0aSs1dcs6KFSHUhw+Ha6+Nepr0U1uXZMRt7mZWYmZL\n",
       "zWyZmV2zh22KzWyRmb1nZhUpn1KkxnvvwamnhiV78z3Y1dalMept7mZWBNwDdAPWAm+Y2XR3XxKz\n",
       "zf7A34Du7r7GzAro6mLJpNdfh7PPhj//GQYMiHqa9FJbl8aKd1rmJGC5u68CMLMpwDnAkphtBgJP\n",
       "uPsaAHf/JA1zSoGbOxd+8YvwIOtevaKeJn103bqkSrxwbw2sjnm9Bqi9tl57YB8zmwe0AP7q7g+l\n",
       "bkQpdNOmwbBh8Nhj4UPUfKW2LqkUL9w9gX3sA3QCzgCaAa+a2Wvuvqyxw4lMnAgjR4Y12U84Iepp\n",
       "0kNtXdIhXrivBdrGvG5LaO+xVgOfuPuXwJdm9hJwPPCNcC8tLd31++LiYoqLixs+sRSMv/0NbrkF\n",
       "XngBjjkm6mnSQ21daquoqKCioqLR+zH3PZdzM9sb+IDQytcBrwMDan2gejThQ9fuQBNgAdDf3d+v\n",
       "tS+v771EdnKHm2+GsWNhzhxo1y7qiVJPbV0SZWa4e4N/OOpt7u5eZWYjgGeBImCMuy8xs0trvv6A\n",
       "uy81s9nAYqAaKK8d7CKJcg+XOc6eHZbsPfTQqCdKPbV1yYR6m3tK30jNXeLYsQMuuwzefTecYz/w\n",
       "wKgnSi21dUlGWpq7SKZUVsIFF8CmTeGxeM2bRz1RaqmtS6Yp3CVyX3wB554LTZrA009D06ZRT5Q6\n",
       "ausSFYW7RGrzZvjpT+HII2HMGNg7j34i1dYlSloVUiKzcSOcdhr84AfhztN8CXatCSPZIE/+Okmu\n",
       "Wb0azjwTfv5z+N3vIF/OVKitS7ZQuEvG/fOfcNZZcMUVcNVVUU+TGjq3LtlG4S4Z9c474elJf/gD\n",
       "DB0a9TSpobYu2UjhLhnzyivQt29YVuC886KepvHU1iWbKdwlI+bMgUGD4KGHoHv3qKdpPLV1yXYK\n",
       "d0m7J56AX/0Kpk6FU06JeprGUVuXXKFwl7QaNw6uvx6efRa+//2op2kctXXJJQp3SZu//CU8Em/e\n",
       "POjQIeppkqe2LrlI4S4p5x6uXZ88OazsePjhUU+UPLV1yVUKd0mp6upw7XpFBbz0EhxySNQTJUdt\n",
       "XXKdwl1SpqoqPOt02bIQ7vvvH/VEyVFbl3ygcJeU+OorGDAAtm4NH55++9tRT9RwauuSTxTu0mif\n",
       "fw79+kHLljB9eli6N9eorUu+0aqQ0iiffRYWAGvbFqZMyb1g1wqOkq/U3CVpH30U7jY94wy4447c\n",
       "W9lRbV3ymZq7JOXDD6FLl7BGTK4Fu9q6FAI1d2mwpUvDkr0jR8Lll0c9TcOorUuhULhLg7z1FvTq\n",
       "BbfeCoMHRz1N4nQljBQahbskbP788CDrsjLo0yfqaRKnti6FSOEuCZk1Cy68MCwp0K1b1NMkRm1d\n",
       "CpnCXeJ65JHwSLwZM6Bz56inSYzauhQ6hbvUq7wcSkvDwzY6dox6mvjU1kUChbvs0W23wb33wosv\n",
       "wlFHRT1NfGrrIrsp3OUb3OGGG8KTk+bPhzZtop6ofmrrIt+kcJevqa4O164vWBCW7D3ooKgnqp/a\n",
       "ukjdFO6yy/btcNFFsHo1zJ0bFgLLVmrrIvVTuAsA27bBz38OO3bA7NnwrW9FPdGeqa2LxKe1ZYQt\n",
       "W6Bnz7AG+5NPZm+wa00YkcSpuRe4TZugRw/o1An+9jcoKop6orqprYs0jJp7AVu3Dk49FU4/He67\n",
       "LzuDXW1dJDlq7gVqxYrwkI1hw+Daa6Oepm5q6yLJU7gXoPfeg5ISuP56+OUvo57mm3QljEjjxT0t\n",
       "Y2YlZrbUzJaZ2TX1bHeimVWZWb/Ujiip9PrrYeGvP/0pO4N90fpFnFh+Im+uf5O3L3ubwccPVrCL\n",
       "JKHe5m5mRcA9QDdgLfCGmU139yV1bHcrMBvQ38QsNW8e9O8PY8ZA795RT/N1ausiqRXvtMxJwHJ3\n",
       "XwVgZlOAc4Altba7HHgcODHVA0pqTJ8Ol1wCjz4KxcVRT/N1OrcuknrxTsu0BlbHvF5T82e7mFlr\n",
       "QuDfV/NHnrLpJCUmToThw2HmzOwKdl0JI5I+8Zp7IkH9F+Bad3cL/x2t/5bOIvfeCzffDC+8AMce\n",
       "G/U0u6mti6RXvHBfC7SNed2W0N5j/RCYUnN+tBXQw8y2u/v02jsrLS3d9fvi4mKKs6lG5hn3EOpj\n",
       "x4YFwNq1i3qiQOfWRepXUVFBRUVFo/dj7nsu52a2N/ABcAawDngdGFD7A9WY7ccBM9x9ah1f8/re\n",
       "S1LHHa65Bp55Bp57Dg49NOqJgti2Xta7TG1dJAFmhrs3uAHV29zdvcrMRgDPAkXAGHdfYmaX1nz9\n",
       "gaSmlbTZsSNc4vjOO+EhGwceGPVEausiUai3uaf0jdTc066yEgYPho8/hqeeghYtop5IbV2ksdLS\n",
       "3CV3fPEFnHce7LtvuCqmadNo51FbF4mWwj0PbN4cbko64ojwAeo++0Q7j66EEYmeVoXMcR9/DKed\n",
       "Bh07woQJ0Qa7rlsXyR5q7jls9Wo466xwOub3v4coz3qorYtkF4V7jlq2LCzZe/nlcPXV0c2hc+si\n",
       "2UnhnoMWLw5PT/rd78J6MVFRWxfJXgr3HPPqq9CnD9x9d3igdRTU1kWyn8I9h8yZA4MGwYMPhodt\n",
       "REFtXSQ3KNxzxNSpcNll4X9POSXz76+2LpJbFO45YPx4uO46mD0bOnXK/PurrYvkHoV7lvvrX+HO\n",
       "O6GiAjp0yOx7q62L5C6Fe5ZyD9euT5oUluw94ojMvr/aukhuU7hnoepquOqq0Nbnz4dDDsnce6ut\n",
       "i+QHhXuWqaqCYcPggw/CA60POCBz7622LpI/FO5Z5KuvYOBA+PzzcNnjt7+dmfdVWxfJPwr3LLF1\n",
       "K/TtCy1bwvTp0KRJZt5XbV0kP2lVyCzw2WdhnZg2bWDKlMwEu1ZwFMlvau4R27AhrOx4+ulwxx2w\n",
       "Vwb+uVVbF8l/au4R+vBD6NIFzj03XMue7mBXWxcpHGruEVm6NDT2q6+GK69M//uprYsUFoV7BN56\n",
       "C3r1gltugQsvTO976UoYkcKkcM+w+fPDaZj774d+/dL7XmrrIoVL4Z5BzzwTmvrDD0O3bul7H7V1\n",
       "EVG4Z8ijj4ZH4k2bBj/6UfreR21dREDhnhHl5VBaGu467dgxPe+hti4isRTuaXb77XDPPWERsPbt\n",
       "0/MeausiUpvCPU3c4YYbwpOT/v73cPdpqqmti8ieKNzToLo6nF9/7bWwFvtBB6X+PdTWRaQ+CvcU\n",
       "274dLr443H06dy7st19q96+2LiKJULin0LZt0L9/CPjZs6FZs9TuX21dRBKlcE+RLVvgnHPg4IPh\n",
       "scdg331Tt2+1dRFpKIV7CmzaBD17wve/D/feC0VFqdu32rqIJEOrQjbSunXQtWv4df/9qQt2reAo\n",
       "Io2h5t4IK1aEh2xccglcey2k6kyJ2rqINJbCPUn/+Ad07w6/+Q386lep2afOrYtIqijck/DGG9C7\n",
       "d3hy0qBBqdmn2rqIpFJC59zNrMTMlprZMjO7po6vDzKzd8xssZm9bGZpWkElevPmhQ9Py8tTE+w6\n",
       "ty4i6RC3uZtZEXAP0A1YC7xhZtPdfUnMZiuAU919s5mVAGVA53QMHKUZM2Do0LDC42mnNX5/ausi\n",
       "ki6JnJY5CVju7qsAzGwKcA6wK9zd/dWY7RcAaVhJJVqTJoVH4s2cCSee2Lh96dy6iKRbIuHeGlgd\n",
       "83oNcHI92w8FZjVmqGxz771w003wwgtw7LGN25fauohkQiLh7onuzMxOAy4GflLX10tLS3f9vri4\n",
       "mOLi4kR3HQn38JzT0aPDAmBHHpn8vtTWRSQRFRUVVFRUNHo/5l5/dptZZ6DU3UtqXl8HVLv7rbW2\n",
       "6whMBUrcfXkd+/F475VN3MO16zNnwnPPwWGNKNixbb2sd5nauogkzMxw9wY3wUSa+0KgvZl9B1gH\n",
       "9AcG1HrzwwnBfn5dwZ5rduwI164vWgQvvgj/9V/J7UdtXUSiEjfc3b3KzEYAzwJFwBh3X2Jml9Z8\n",
       "/QHgt8ABwH014bXd3U9K39jpU1kJgwfDxo3hHHuLFsntR+fWRSRKcU/LpOyNcuC0zBdfwM9+Bnvv\n",
       "DY88Ak2bNnwfausikkrpPC1TEDZvDnedHn44jBsH++zT8H2orYtIttCqkMDHH8Ppp8Nxx8GDDzY8\n",
       "2HWXqYhkm4Jv7mvWhJUd+/WDP/6x4Ss7qq2LSDYq6HBftgzOOitcGTNyZMO+V+fWRSSbFWy4L14M\n",
       "PXpAaSkMG9aw71VbF5FsV5Dh/uqr0KcP3HVXeKB1otTWRSRXFFy4P/88DBgAEyaEpXsTpbYuIrmk\n",
       "oML9ySfh0kth6lTo0iWx71FbF5FcVDDhPmFCWCtm9mzo1Cmx71FbF5FcVRDhftddcPvt4SlKRx8d\n",
       "f3u1dRHJdXkd7u7whz/AQw/B/PlwxBHxv0dtXUTyQd6Ge3V1eHLS3Lkh2P/7v+vfXm1dRPJJXoZ7\n",
       "VRUMHw5Ll0JFBRxwQP3bq62LSL7Ju3D/6isYNCgsBPbcc9C8+Z63VVsXkXyVV+G+dWtYI6Z5c3j6\n",
       "aWjSZM/bqq2LSD7Lm1Uh//3vsE7MYYeFtdj3FOxawVFECkFeNPcNG6B7dyguhjvvhL328E+W2rqI\n",
       "FIqcb+4ffhjuNu3bF/7857qDXW1dRApNTjf3pUtDY7/qKrjyyrq3UVsXkUKUs+G+aFFY+Ovmm2HI\n",
       "kG9+XVfCiEghy8lwnz8fzj0X7r8/XB1Tm9q6iBS6nAv32bPhggtg0qRwdUwstXURkSCnwv2xx2DE\n",
       "CJg2DX78469/TW1dRGS3nAn30aPht78Nd50ef/zuP1dbFxH5ppwI9zvugLvvhhdfhPbtd/+52rqI\n",
       "SN2yOtzd4X//Fx5/PHyI2rZt+HO1dRGR+mVtuFdXwxVXwCuvhGA/6KDw52rrIiLxZWW4b98OF18M\n",
       "q1aFpyftt5/auohIQ2RduG/bBv37Q2UlPPssNGumti4i0lBZtbbMli3Qqxc0bRoud9y7idaEERFJ\n",
       "RtY0908/hR49oGPHcOfp4o1q6yIiycqK5r5+PXTtCqeeCvfcV8nvX1JbFxFpjMib+8qV0K0bDB0K\n",
       "JUMWcdJotXURkcaKNNzffz8s2Tvy2ko2HXMjJZN0JYyISCpEFu5vvAG9e8OIGxcxZvsQ2q5XWxcR\n",
       "SZW459zNrMTMlprZMjO7Zg/b3FXz9XfM7Afx9llRAT17V1JcOoq7PtW5dRGRVKs33M2sCLgHKAGO\n",
       "AQaY2fdqbdMTOMrd2wPDgfvq2+fTT0PfXy6i5f87kc9bvsnbl73N4OMHF9RpmIqKiqhHyBo6Frvp\n",
       "WOymY9F48Zr7ScByd1/l7tuBKcA5tbY5G5gA4O4LgP3N7JC6dvbgpEp+8cAobHB3Rp1ZuG1dP7i7\n",
       "6VjspmOxm45F48U7594aWB3zeg1wcgLbtAE21N7Z0AUn8uOftmXyQJ1bFxFJp3jh7gnup/Y5lTq/\n",
       "7+beV3N1N10JIyKSbua+5/w2s85AqbuX1Ly+Dqh291tjtrkfqHD3KTWvlwJd3X1DrX0l+g+FiIjE\n",
       "cPcGN+J4zX0h0N7MvgOsA/oDA2ptMx0YAUyp+cfg37WDPdnhREQkOfWGu7tXmdkI4FmgCBjj7kvM\n",
       "7NKarz/g7rPMrKeZLQe2AhelfWoREalXvadlREQkN6V84bB03PSUq+IdCzMbVHMMFpvZy2bWMYo5\n",
       "MyGRn4ua7U40syoz65fJ+TIlwb8fxWa2yMzeM7OKDI+YMQn8/WhlZrPN7O2aYzEkgjEzwszGmtkG\n",
       "M3u3nm0alpvunrJfhFM3y4HvAPsAbwPfq7VNT2BWze9PBl5L5QzZ8ivBY/EjYL+a35cU8rGI2W4u\n",
       "8DRwbtRzR/QzsT/wD6BNzetWUc8d4bEoBW7eeRyATcDeUc+epuPRBfgB8O4evt7g3Ex1c0/pTU85\n",
       "Lu6xcPdX3X1zzcsFhPsD8lEiPxcAlwOPAx9ncrgMSuQ4DASecPc1AO7+SYZnzJREjsV6oGXN71sC\n",
       "m9y9KoMzZoy7zwc+q2eTBudmqsO9rhuaWiewTT6GWiLHItZQYFZaJ4pO3GNhZq0Jf7l3Ll+Rjx8G\n",
       "JfIz0R440MzmmdlCM7sgY9NlViLHohw41szWAe8AV2ZotmzU4NxM9aqQKb3pKccl/P/JzE4DLgZ+\n",
       "kr5xIpXIsfgLcK27u4W73PLx0tlEjsM+QCfgDKAZ8KqZvebuy9I6WeYlcix+A7zt7sVm9l1gjpkd\n",
       "7+5b0jxbtmpQbqY63NcCbWNetyX8C1PfNm1q/izfJHIsqPkQtRwocff6/rMslyVyLH5IuFcCwvnV\n",
       "Hma23d2nZ2bEjEjkOKwGPnH3L4Evzewl4Hgg38I9kWPxY+BGAHf/PzNbCXQg3H9TaBqcm6k+LbPr\n",
       "picz25dw01Ptv5zTgcGw6w7YOm96ygNxj4WZHQ5MBc539+URzJgpcY+Fux/p7u3cvR3hvPsv8yzY\n",
       "IbG/H9OAU8ysyMyaET48ez/Dc2ZCIsdiKdANoOb8cgdgRUanzB4Nzs2UNnfXTU+7JHIsgN8CBwD3\n",
       "1TTW7e5+UlQzp0uCxyLvJfj3Y6mZzQYWA9VAubvnXbgn+DNxEzDOzN4hFNFfu/unkQ2dRmY2GegK\n",
       "tDKz1cAowim6pHNTNzGJiOShlN/EJCIi0VO4i4jkIYW7iEgeUriLiOQhhbuISB5SuIuI5CGFu4hI\n",
       "HlK4i4jkof8Prx7w+RKAvMwAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1257a1b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(sgd_l1_analysis.actual, sgd_l1_predicted_copy)\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# RNN using LSTM \n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-rolled.png\"/ width=\"80px\" height=\"80px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-unrolled.png\"/ width=\"400px\" height=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LSTM3-chain.png\"/ width=\"800px\" height=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_source: http://colah.github.io/posts/2015-08-Understanding-LSTMs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import one_hot,text_to_word_sequence,base_filter\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_male_posts = []\n",
    "filtered_female_posts = []\n",
    "\n",
    "for post_male in male_posts:\n",
    "    if len(post_male) == 0:\n",
    "        continue\n",
    "    filtered_male_posts.append(post_male)\n",
    "\n",
    "for post_female in female_posts:\n",
    "    if len(post_female) == 0:\n",
    "        continue\n",
    "    filtered_female_posts.append(post_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text processing - one hot builds index of the words\n",
    "male_one_hot = []\n",
    "female_one_hot = []\n",
    "n = 30000\n",
    "for post in filtered_male_posts:\n",
    "    try:\n",
    "        male_one_hot.append(one_hot(post,n,split=\" \",filters=base_filter(),lower=True))\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "for post in filtered_female_posts:\n",
    "    try:\n",
    "        female_one_hot.append(one_hot(post,n,split=\" \",filters=base_filter(),lower=True))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "concatenate_array_rnn = np.concatenate((np.zeros(len(male_one_hot)),np.ones(len(female_one_hot))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((female_one_hot,male_one_hot)),concatenate_array_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train_rnn shape:', (3706, 100), (3706,))\n",
      "('x_test_rnn shape:', (927, 100), (927,))\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "dimension = 128\n",
    "input_dimension = 128\n",
    "output_dimension = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, dimension))\n",
    "model.add(LSTM(input_dimension, output_dimension))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3706 samples, validate on 927 samples\n",
      "Epoch 0\n",
      "3706/3706 [==============================] - 55s - loss: 0.2495 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 1.0000\n",
      "Epoch 1\n",
      "3706/3706 [==============================] - 48s - loss: 0.2489 - acc: 1.0000 - val_loss: 0.2487 - val_acc: 1.0000\n",
      "Epoch 2\n",
      "3706/3706 [==============================] - 51s - loss: 0.2485 - acc: 1.0000 - val_loss: 0.2485 - val_acc: 1.0000\n",
      "Epoch 3\n",
      "3706/3706 [==============================] - 55s - loss: 0.2485 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb59550>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_rnn,y_train_rnn,batch_size=32,nb_epoch=4,validation_data=(x_test_rnn,y_test_rnn),show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(x_test_rnn,y_test_rnn,batch_size=32,show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TFIDF Vectorizer as an input instead of one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', norm='l2')\n",
    "tfidf_male = vectorizer.fit_transform(clean_male_post_list)\n",
    "tfidf_female = vectorizer.fit_transform(clean_female_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened_array_tfidf_male = tfidf_male.toarray()\n",
    "flattened_array_tfidf_female = tfidf_male.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatenate_array_rnn = np.concatenate((np.zeros(len(flattened_array_tfidf_male)),np.ones(len(flattened_array_tfidf_female))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rnn,x_test_rnn,y_train_rnn,y_test_rnn = train_test_split(np.concatenate((flattened_array_tfidf_male,flattened_array_tfidf_female)),concatenate_array_rnn,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "# x_train_rnn = sequence.pad_sequences(x_train_rnn,maxlen=maxlen)\n",
    "# x_test_rnn = sequence.pad_sequences(x_test_rnn,maxlen=maxlen)\n",
    "# print('x_train_rnn shape:', x_train_rnn.shape,y_train_rnn.shape)\n",
    "# print('x_test_rnn shape:', x_test_rnn.shape,y_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, 128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_rnn,y_train_rnn,batch_size=32,nb_epoch=4,validation_data=(x_test_rnn,y_test_rnn),show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score,acc = model.evaluate(x_test_rnn,y_test_rnn,batch_size=32,show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Generation using RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading all the male text data into one string\n",
    "male_post = ' '.join(filtered_male_posts[:2])\n",
    "\n",
    "#building character set for the male posts\n",
    "character_set_male = set(male_post)\n",
    "#building two indices - character index and index of character\n",
    "char_indices = dict((c, i) for i, c in enumerate(character_set_male))\n",
    "indices_char = dict((i, c) for i, c in enumerate(character_set_male))\n",
    "\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(male_post) - maxlen, step):\n",
    "    sentences.append(male_post[i : i + maxlen])\n",
    "    next_chars.append(male_post[i + maxlen])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 20, 32) (335, 32)\n",
      "(335, 20, 32) (335, 32)\n"
     ]
    }
   ],
   "source": [
    "#Vectorisation of input\n",
    "x_male = np.zeros((len(male_post),maxlen,len(character_set_male)),dtype=np.bool)\n",
    "y_male = np.zeros((len(male_post),len(character_set_male)),dtype=np.bool)\n",
    "\n",
    "print x_male.shape,y_male.shape\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_male[i, t, char_indices[char]] = 1\n",
    "    y_male[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print x_male.shape,y_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Building the model to generate text with 2 layers\n",
    "auto_text_generating_male_model = Sequential()\n",
    "auto_text_generating_male_model.add(LSTM(len(character_set_male),512,return_sequences=True))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(LSTM(512,512,return_sequences=False))\n",
    "auto_text_generating_male_model.add(Dropout(0.2))\n",
    "auto_text_generating_male_model.add(Dense(512,len(character_set_male)))\n",
    "auto_text_generating_male_model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_text_generating_male_model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to sample an index from a probability array\n",
    "def sample(a, diversity=0.75):\n",
    "    if random.random() > diversity:\n",
    "        return np.argmax(a)\n",
    "    while 1:\n",
    "        i = random.randint(0, len(a)-1)\n",
    "        if a[i] > random.random():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 1)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 11s - loss: 0.2502    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \" with since the star\"\n",
      "4ccgccccaoaaaaaplpk0\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \" with since the star\"\n",
      "kkkkkwhptuffc0f,r000\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \" with since the star\"\n",
      "dyyyy2Tyt4aeeifedIdd\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \" with since the star\"\n",
      "0lfw.vnryoryyhg4o,ei\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 2)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2498    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"et to hang out with \"\n",
      "yv yyyyvyym0mmeeewwf\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \"et to hang out with \"\n",
      ",22I22T22v2222I222ln\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \"et to hang out with \"\n",
      "eYrrgapu drr0m yfuyy\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \"et to hang out with \"\n",
      "If,,4fesn,dkhdt, s2'\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 3)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 11s - loss: 0.2493    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"ly get half of the p\"\n",
      "ccci2vvlvrra2aiaaaf.\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \"ly get half of the p\"\n",
      "''''d'''''hhhhahehhh\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \"ly get half of the p\"\n",
      "wscyvvrnvowerurTuplc\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \"ly get half of the p\"\n",
      "er3aosemcmcehaacyfpa\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 4)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2489    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"d world country. It \"\n",
      "'.'gvvvccccccmaaaaTg\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \"d world country. It \"\n",
      " h22o2222lgnnn,nnen0\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \"d world country. It \"\n",
      "ykIcyy,0i330d.yy.yyy\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \"d world country. It \"\n",
      "eYT3'dYY,2saYp0T'l'I\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 5)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2484    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \" i'm gonna work on m\"\n",
      "ccccccYcaaa2aakpakkk\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \" i'm gonna work on m\"\n",
      "Isg0.vvuvvyyy3wyuyy3\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \" i'm gonna work on m\"\n",
      "vcp4Iftw'Ig oIwtlvwv\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \" i'm gonna work on m\"\n",
      "T3ymfv ,kkgykamfawf'\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 6)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2481    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"20 hour famine at my\"\n",
      "vv333ooce cIccaaaaaf\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \"20 hour famine at my\"\n",
      "    y u Imeiyyssssoo\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \"20 hour famine at my\"\n",
      "rnfTohvrdyptyha0lmer\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \"20 hour famine at my\"\n",
      "yuuywyc,'euklrr4igrr\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 7)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2477    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"paper done. Then i a\"\n",
      "TTtd'TTTTlTymmmm'mIm\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \"paper done. Then i a\"\n",
      "cccp3cccIc,raa,aaa p\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.6)\n",
      "----- Generating with seed: \"paper done. Then i a\"\n",
      "rr,my0m,yY. wcp rlIr\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.8)\n",
      "----- Generating with seed: \"paper done. Then i a\"\n",
      "iTypeTc.cIi3Ielf'd s\n",
      "()\n",
      "()\n",
      "--------------------------------------------------\n",
      "('Iteration', 8)\n",
      "Epoch 0\n",
      "335/335 [==============================] - 10s - loss: 0.2473    \n",
      "()\n",
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \", I am glad I don't \"\n",
      "eeeouuTTd   TTkT faa\n",
      "()\n",
      "()\n",
      "('----- diversity:', 0.4)\n",
      "----- Generating with seed: \", I am glad I don't \"\n",
      "0ccrlcccIaIa2aaaakdk"
     ]
    }
   ],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1,10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    auto_text_generating_male_model.fit(x_male, y_male, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(male_post) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = male_post[start_index : start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for iteration in range(400):\n",
    "            try:\n",
    "                x = np.zeros((1, maxlen, len(character_set_male)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = auto_text_generating_male_model.predict(x, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                #sys.stdout.write(next_char)\n",
    "                #sys.stdout.flush()\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        print sentence\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
