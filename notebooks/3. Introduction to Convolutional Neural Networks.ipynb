{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks\n",
    "\n",
    "**Goal** : This notebook explains how to implement a simple convolutional neural network model. \n",
    "\n",
    "### History/Milestones for CNN\n",
    "\n",
    "1. 1980 Kunihiko Fukushima introduction\n",
    "2. 1998 Le Cun (Backpropagation) \n",
    "3. Contests won (2011& 2014 MINST Handwritten Dataset, Kaggle competitions, etc)\n",
    "4. ImageNet success story : Alex Net(2012)\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/1_cnn_accuracy_2012.png\" height=\"520\" width=\"520\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 650M\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import sys\n",
    "import six.moves.cPickle\n",
    "from six.moves import range\n",
    "import os\n",
    "\n",
    "def cifar10_load_batch(label_key='labels'):\n",
    "    features_path = \"../data/cifar_features\"\n",
    "    labels_path = \"../data/cifar_labels\"\n",
    "    \n",
    "    f = open(features_path, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        d = six.moves.cPickle.load(f)\n",
    "    else:\n",
    "        d = six.moves.cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        for k, v in d.items():\n",
    "            del(d[k])\n",
    "            d[k.decode(\"utf8\")] = v\n",
    "    f.close()\n",
    "    data = np.array(d)\n",
    "    \n",
    "    f = open(labels_path, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        d = six.moves.cPickle.load(f)\n",
    "    else:\n",
    "        d = six.moves.cPickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        for k, v in d.items():\n",
    "            del(d[k])\n",
    "            d[k.decode(\"utf8\")] = v\n",
    "    f.close()\n",
    "    labels = np.array(d)\n",
    "\n",
    "    #data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def cifar10_load_data():\n",
    "\n",
    "#     nb_test_samples = 10000\n",
    "#     nb_train_samples = 50000\n",
    "\n",
    "#     X_train = np.zeros((nb_train_samples, 3, 32, 32), dtype=\"uint8\")\n",
    "#     y_train = np.zeros((nb_train_samples,), dtype=\"uint8\")\n",
    "\n",
    "#     for i in range(1, 6):\n",
    "#         fpath = os.path.join(path, 'data_batch_' + str(i))\n",
    "#         data, labels = cifar10_load_batch(fpath)\n",
    "#         X_train[(i-1)*10000:i*10000, :, :, :] = data\n",
    "#         y_train[(i-1)*10000:i*10000] = labels\n",
    "    \n",
    "#     fpath = os.path.join(path, 'test_batch')\n",
    "#     X_test, y_test = cifar10_load_batch(fpath)\n",
    "\n",
    "#     y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "#     y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    X_train, y_train = cifar10_load_batch()\n",
    "\n",
    "    return (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train) = cifar10_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 32, 32)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(10000,3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "Create 2 categories of data:\n",
    "* 5000 cats\n",
    "* 5000 others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3073)\n",
      "(10000, 3072)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train_reshaped, dtype=float)\n",
    "df = pd.concat([df, pd.DataFrame(y_train)], axis=1)\n",
    "\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.columns = range(0,3073)\n",
    "cats = df[df[3072] == 3].copy()\n",
    "cats[3072] = 1\n",
    "dogs = df[df[3072] != 5]\n",
    "dogs = dogs[:5000].copy()\n",
    "dogs[3072] = 0\n",
    "df = cats.append(dogs)\n",
    "print df.shape\n",
    "\n",
    "data = np.array(df.ix[:, :3071])\n",
    "labels = np.array(df[3072])\n",
    "\n",
    "data.shape\n",
    "X_train = data\n",
    "Y_train = np_utils.to_categorical(labels)\n",
    "print X_train.shape\n",
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for faster convergence\n",
    "dims = 64\n",
    "# dims = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sequential model & add layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], dims , init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(dims , dims, init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(dims, Y_train.shape[1], init='uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2.65 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "10000/10000 [==============================] - 1s - loss: 0.5006 - acc: 0.4993     \n",
      "Epoch 1\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 0\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 1\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 0\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 1\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 0\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "Epoch 1\n",
      "10000/10000 [==============================] - 1s - loss: 0.5000 - acc: 0.5000     \n",
      "1 loops, best of 3: 2.46 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit model.fit(X_train, Y_train, nb_epoch=2, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = cifar10_load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each image has 3 channel (RGB) & is of size 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=uint32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "Create 2 categories of data:\n",
    "* 5000 cats\n",
    "* 5000 others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = zip(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cats(x):\n",
    "    if x[1][0] == 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_others(x):\n",
    "    if x[1][0] != 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catz = filter(get_cats, z)\n",
    "x_cat, y_cat = zip(*catz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otherz = filter(get_others, z)\n",
    "otherz = otherz[:5000]\n",
    "x_other, y_other = zip(*otherz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_cats = np.array(x_cat)\n",
    "x_others = np.array(x_other)\n",
    "\n",
    "X_train = np.concatenate([x_cats,x_others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_cats = np.array(y_cat)\n",
    "y_others = np.array(y_other)\n",
    "\n",
    "y_train = np.concatenate([y_cats,y_others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[y_train == 3] = 1\n",
    "y_train[y_train != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ..., \n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=uint32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape y_train to represent 2 categories - Cats & Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 2)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sequential model, add convolutional layers with activation functions & regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This works - Just one layer of Convolution\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32*34*34, 256))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "10000/10000 [==============================] - 9s - loss: 6.7539 - acc: 0.5034     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1173a9d10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This works - Just one layer of Convolution and max pooling\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32*17*17, 256))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "10000/10000 [==============================] - 12s - loss: 7.9104 - acc: 0.5046    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190f03190>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This works - Just one layer of Convolution but no full padding\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3)) \n",
    "#model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32*30*30, 256))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "10000/10000 [==============================] - 16s - loss: 7.9239 - acc: 0.5000    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132e08850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This works - all layers once\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "#model.add(Convolution2D(32, 3, 3, 3)) \n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(32, 32, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32*34*34, 256))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "10000/10000 [==============================] - 18s - loss: 0.6971 - acc: 0.4949    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1891fc050>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This works - all layers once\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32*16*16, 256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is blank cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 32, 3, 3, border_mode='full')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 64, 3, 3)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64*8*8, 256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import six.moves.cPickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/rajni_cigar\", \"rb\") as rf:\n",
    "    l_data = six.moves.cPickle.loads(rf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unzipped = zip(*l_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.array(unzipped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(unzipped[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_LABELS = np_utils.to_categorical(labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 32, 3, 3, border_mode='full')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 64, 3, 3)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64*8*8, 256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, 2))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data\n",
    "Y_train = Y_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, show_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([labels, predict]).T\n",
    "df.columns = ['label', 'prediction']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/2_data_augmentation.png\" height=\"520\" width=\"820\">\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "[Source](http://benanne.github.io/2015/03/17/plankton.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "Problem with Stochastic Gradient Descent are Valleys (local minima). Bounce up and down the walls and don‘t descent the slope. What's to our rescue? **Momentum**. Nesterov Momentum (NAG) \n",
    "\n",
    "<img style=\"float: left;\" src=\"img/3_ momentum.png\" height=\"520\" width=\"620\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
